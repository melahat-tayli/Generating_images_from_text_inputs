# Generating images from text inputs
## Project Overview:
OpenAI's DALL-E and DALL-E 2 are groundbreaking AI systems capable of generating images from textual descriptions. To fully understand these and similar systems, it's essential to delve into their underlying architecture and properties. One notable research project in this area is Reed et al.'s "Generative Adversarial Text to Image Synthesis."

Their goal is to explore various network architectures, including DCGANs, GANs, and diffusion models, for text-to-image generation and compare their performance.

In this repository, I've implemented image processing techniques and created text embeddings from textual inputs, which are crucial for training these neural networks.